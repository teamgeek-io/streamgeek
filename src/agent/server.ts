import { Hono } from "hono";
import { cors } from "hono/cors";
import { streamSSE } from "hono/streaming";

import fs from "fs/promises";
import { FileStore } from "@tus/file-store";
import { Server } from "@tus/server";
import { z } from "zod";
import { zValidator } from "@hono/zod-validator";
import { processPresets } from "./transcoder";
import { EventEmitter } from "events";
import { uploadFolderToS3 } from "./s3";
import { apiKeyAuth } from "@/shared/apiAuth";
import { orchestratorClient } from "./orchestratorClient";
import { generateUploadToken } from "./tokenUtils";
import { uploadTokenAuth } from "./uploadAuth";

const tusServer = new Server({
  path: "/upload",
  datastore: new FileStore({ directory: "./input" }),
  allowedHeaders: [
    "authorization",
    "content-type",
    "x-requested-with",
    "x-forwarded-for",
    "x-forwarded-proto",
  ],
  relativeLocation: true,
  respectForwardedHeaders: true,
});

const transcodingEvents = new EventEmitter();

const COMPLETE_MESSAGE = "complete";
const FAILED_MESSAGE = "failed";

const agentApp = new Hono()
  .use("*", cors({ origin: process.env.ORCHESTRATOR_URL! }))
  .all("/upload*", uploadTokenAuth, async (c) => {
    return tusServer.handleWeb(c.req.raw);
  })
  .get("/progress/:jobId", uploadTokenAuth, async (c) => {
    const { jobId } = c.req.param();
    return streamSSE(c, async (stream) => {
      const existingCompleteJobRes = await orchestratorClient.orchestrator.job[
        ":jobId"
      ].$get({
        param: {
          jobId,
        },
      });

      const { job } = await existingCompleteJobRes.json();

      if (job?.status === "done") {
        // Catches the case where the job is completed before the client connects
        stream.writeSSE({
          data: "Job already completed",
          event: "complete",
          id: jobId,
        });
        await stream.close();
        return;
      }

      let jobEnded = false;

      // Send initial connection message
      stream.writeSSE({
        data: "Connected to transcoding progress stream",
        event: "connected",
        id: jobId,
      });

      // Set up event listener for transcoding progress
      const progressHandler = async (message: string) => {
        if (message === COMPLETE_MESSAGE) {
          stream.writeSSE({
            data: message,
            event: "complete",
            id: jobId,
          });
          jobEnded = true;
          return;
        }

        if (message === FAILED_MESSAGE) {
          stream.writeSSE({
            data: message,
            event: "failed",
            id: jobId,
          });
          jobEnded = true;
          return;
        }

        stream.writeSSE({
          data: message,
          event: "progress",
          id: jobId,
        });
      };

      transcodingEvents.on(jobId, progressHandler);

      // Handle client disconnect
      stream.onAbort(() => {
        console.log(`Client disconnected from job ${jobId}`);
        transcodingEvents.off(jobId, progressHandler);
      });

      try {
        // Sleep for 1 second until the job is complete
        while (!jobEnded) {
          await stream.sleep(1000);
        }
      } catch (error) {
        // Stream was closed/aborted
        console.log(`Stream closed for job ${jobId}`);
        transcodingEvents.off(jobId, progressHandler);
      }
    });
  })
  .use("*", (c, next) => {
    // upload and progress routes use their own auth middleware
    if (
      c.req.path.startsWith("/upload") ||
      c.req.path.startsWith("/progress")
    ) {
      return next();
    }
    return apiKeyAuth(c, next, process.env.API_KEY!);
  })
  .get("/", (c) => {
    return c.text("Hello Agent!");
  })
  .get("/ping", async (c) => {
    const agentUrl = process.env.AGENT_URL;
    const agentId = await fs.readFile("agent_id.txt", "utf8");
    return c.json({
      agentId,
      agentUrl,
    });
  })
  .post(
    "/start/:jobId",
    zValidator("json", z.object({ sourceFileId: z.string() })),
    async (c) => {
      const { jobId } = c.req.param();
      const { sourceFileId } = c.req.valid("json");

      const videoId = (
        await (
          await orchestratorClient.orchestrator.job[":jobId"].$get({
            param: { jobId },
          })
        ).json()
      ).job?.videoId;

      if (!videoId) {
        return c.json({ error: "Video for job not found" }, 400);
      }

      // ToDo: we probably want to use the video id in the first place
      // this sourceFileId is generated by tus/uppy.
      const inputPath = new URL(
        `file://${process.cwd()}/input/${sourceFileId}`
      );

      const outputFolder = new URL(`file://${process.cwd()}/output`);

      // We sneaky DONT AWAIT here to avoid blocking the request
      processPresets(inputPath, videoId, outputFolder, (message) => {
        transcodingEvents.emit(jobId, message);
      })
        .then(async () => {
          transcodingEvents.emit(jobId, "Uploading to R2");

          await orchestratorClient.orchestrator.job[":jobId"].$patch({
            param: {
              jobId,
            },
            json: { status: "uploading" },
          });

          await uploadFolderToS3({
            localFolderPath: `${outputFolder.pathname}/${videoId}`,
            bucketName: process.env.S3_BUCKET!,
            s3Prefix: videoId,
            onProgress: (message) => {
              transcodingEvents.emit(jobId, message);
            },
          });

          // Delete input file and input file metadata
          await fs.rm(`${inputPath.pathname}`);
          await fs.rm(`${inputPath.pathname}.json`);

          // Delete output folder
          await fs.rm(`${outputFolder.pathname}`, {
            recursive: true,
          });

          await orchestratorClient.orchestrator.video[":videoId"].$patch({
            param: {
              videoId,
            },
            json: {
              thumbnailUrl: `${process.env.S3_PUBLIC_ACCESS}/${videoId}/thumbnail.jpeg`,
              playlistUrl: `${process.env.S3_PUBLIC_ACCESS}/${videoId}/playlist.m3u8`,
            },
          });

          await orchestratorClient.orchestrator.job[":jobId"].$patch({
            param: {
              jobId,
            },
            json: { status: "done" },
          });

          transcodingEvents.emit(jobId, COMPLETE_MESSAGE);
        })
        .catch(async (error) => {
          console.error("Error transcoding/uploading", error);
          await orchestratorClient.orchestrator.job[":jobId"].$patch({
            param: {
              jobId,
            },
            json: { status: "failed" },
          });
          transcodingEvents.emit(jobId, FAILED_MESSAGE);
        });

      return c.json({
        success: true,
      });
    }
  )
  .post("/generate-token/:jobId", async (c) => {
    const { jobId } = c.req.param();

    const jobRes = await (
      await orchestratorClient.orchestrator.job[":jobId"].$get({
        param: { jobId },
      })
    ).json();

    if (!jobRes.job) {
      return c.json({ error: "Job not found" }, 404);
    }

    const job = jobRes.job;

    if (job.status !== "queued" && job.status !== "encoding") {
      return c.json({ error: "Job is not queued" }, 400);
    }

    const token = generateUploadToken(jobId);

    return c.json({
      token,
    });
  });
export type AgentApp = typeof agentApp;

export default agentApp;
