import { Hono } from "hono";
import { cors } from "hono/cors";
import { streamSSE } from "hono/streaming";

import fs from "fs/promises";
import { FileStore } from "@tus/file-store";
import { Server } from "@tus/server";
import { z } from "zod";
import { zValidator } from "@hono/zod-validator";
import { processPresets } from "./transcoder";
import { EventEmitter } from "events";
import createOrchestratorClient from "../orchestrator/client";
import { uploadFolderToS3 } from "./s3";

const tusServer = new Server({
  path: "/upload",
  datastore: new FileStore({ directory: "./input" }),
});

const transcodingEvents = new EventEmitter();

const COMPLETE_MESSAGE = "complete";

const orchestratorClient = createOrchestratorClient(
  process.env.ORCHESTRATOR_URL!
);

const agentApp = new Hono()
  .use("*", cors({ origin: process.env.ORCHESTRATOR_URL! })) // TODO: restrict to only the web app
  .get("/", (c) => {
    return c.text("Hello Agent!");
  })
  .get("/ping", async (c) => {
    const agentUrl = process.env.AGENT_URL;
    const agentId = await fs.readFile("agent_id.txt", "utf8");
    return c.json({
      agentId,
      agentUrl,
    });
  })
  .post(
    "/start/:jobId",
    zValidator("json", z.object({ sourceFileId: z.string() })),
    async (c) => {
      const { jobId } = c.req.param();
      const { sourceFileId } = c.req.valid("json");

      const videoId = (
        await (
          await orchestratorClient.orchestrator.job[":jobId"].$get({
            param: { jobId },
          })
        ).json()
      ).job?.videoId;

      if (!videoId) {
        return c.json({ error: "Video for job not found" }, 400);
      }

      // ToDo: we probably want to use the video id in the first place
      // this sourceFileId is generated by tus/uppy.
      const inputPath = new URL(
        `file://${process.cwd()}/input/${sourceFileId}`
      );

      const outputFolder = new URL(`file://${process.cwd()}/output`);

      // We sneaky DONT AWAIT here to avoid blocking the request
      processPresets(inputPath, videoId, outputFolder, (message) => {
        transcodingEvents.emit(jobId, message);
      }).then(async () => {
        transcodingEvents.emit(jobId, "Uploading to R2");

        await orchestratorClient.orchestrator.job[":jobId"].$patch({
          param: {
            jobId,
          },
          json: { status: "uploading" },
        });

        try {
          await uploadFolderToS3({
            localFolderPath: `${outputFolder.pathname}/${videoId}`,
            bucketName: process.env.S3_BUCKET!,
            s3Prefix: videoId,
          });

          // Delete input file and input file metadata
          await fs.rm(`${inputPath.pathname}`);
          await fs.rm(`${inputPath.pathname}.json`);

          // Delete output folder
          await fs.rm(`${outputFolder.pathname}`, {
            recursive: true,
          });
        } catch (error) {
          console.error("Error uploading to S3", error);
          await orchestratorClient.orchestrator.job[":jobId"].$patch({
            param: {
              jobId,
            },
            json: { status: "failed" },
          });
        }

        await orchestratorClient.orchestrator.job[":jobId"].$patch({
          param: {
            jobId,
          },
          json: { status: "done" },
        });

        transcodingEvents.emit(jobId, COMPLETE_MESSAGE);
      });

      return c.json({
        success: true,
      });
    }
  )
  .get("/progress/:jobId", async (c) => {
    const { jobId } = c.req.param();
    return streamSSE(c, async (stream) => {
      const existingCompleteJobRes = await orchestratorClient.orchestrator.job[
        ":jobId"
      ].$get({
        param: {
          jobId,
        },
      });

      const { job } = await existingCompleteJobRes.json();

      if (job?.status === "done") {
        // Catches the case where the job is completed before the client connects
        stream.writeSSE({
          data: "Job already completed",
          event: "complete",
          id: jobId,
        });
        await stream.close();
        return;
      }

      let jobCompleted = false;

      // Send initial connection message
      stream.writeSSE({
        data: "Connected to transcoding progress stream",
        event: "connected",
        id: jobId,
      });

      // Set up event listener for transcoding progress
      const progressHandler = async (message: string) => {
        if (message === COMPLETE_MESSAGE) {
          stream.writeSSE({
            data: message,
            event: "complete",
            id: jobId,
          });
          jobCompleted = true;
          return;
        }

        stream.writeSSE({
          data: message,
          event: "progress",
          id: jobId,
        });
      };

      transcodingEvents.on(jobId, progressHandler);

      // Handle client disconnect
      stream.onAbort(() => {
        console.log(`Client disconnected from job ${jobId}`);
        transcodingEvents.off(jobId, progressHandler);
      });

      try {
        // Sleep for 1 second until the job is complete
        while (!jobCompleted) {
          await stream.sleep(1000);
        }
      } catch (error) {
        // Stream was closed/aborted
        console.log(`Stream closed for job ${jobId}`);
        transcodingEvents.off(jobId, progressHandler);
        // clearInterval(heartbeatInterval);
      }
    });
  })
  .all("/upload*", (c) => {
    return tusServer.handleWeb(c.req.raw);
  });

export type AgentApp = typeof agentApp;

export default agentApp;
